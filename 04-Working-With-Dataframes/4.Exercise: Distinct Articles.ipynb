{"cells":[{"cell_type":"markdown","source":["# Introduction to DataFrames Lab\n## Distinct Articles"],"metadata":{}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Instructions\n\nIn the cell provided below, write the code necessary to count the number of distinct articles in our data set.\n0. Copy and paste all you like from the previous notebook.\n0. Read in our parquet files.\n0. Apply the necessary transformations.\n0. Assign the count to the variable `totalArticles`\n0. Run the last cell to verify that the data was loaded correctly.\n\n**Bonus**\n\nIf you recall from the beginning of the previous notebook, the act of reading in our parquet files will trigger a job.\n0. Define a schema that matches the data we are working with.\n0. Update the read operation to use the schema."],"metadata":{}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Show Your Work"],"metadata":{}},{"cell_type":"code","source":["(source, sasEntity, sasToken) = getAzureDataSource()\nspark.conf.set(sasEntity, sasToken)\n\npath = source + \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\""],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# TODO\n# Replace <<FILL_IN>> with your code. \n\n# First see schema of df\ndf = (spark                    # Our SparkSession & Entry Point\n  .read                        # Our DataFrameReader\n  .parquet(path)                 # Read in the parquet files\n)\ntotalArticles = df.count() # Identify the total number of records remaining.\n\nprint(\"Distinct Articles: {0:,}\".format(totalArticles))\n\ndf.printSchema() \n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Distinct Articles: 2,345,943\nroot\n-- project: string (nullable = true)\n-- article: string (nullable = true)\n-- requests: integer (nullable = true)\n-- bytes_served: long (nullable = true)\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["df = (spark                    # Our SparkSession & Entry Point\n  .read                        # Our DataFrameReader\n  .parquet(path)                 # Read in the parquet files\n  .select('article')                 # Reduce the columns to just the one\n  .distinct()                  # Produce a unique set of values\n)\ntotalArticles = df.count() # Identify the total number of records remaining.\n\nprint(\"Distinct Articles: {0:,}\".format(totalArticles))\n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Distinct Articles: 1,783,138\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Verify Your Work\nRun the following cell to verify that your `DataFrame` was created properly."],"metadata":{}},{"cell_type":"code","source":["expected = 1783138\nassert totalArticles == expected, \"Expected the total to be \" + str(expected) + \" but found \" + str(totalArticles)\n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":11}],"metadata":{"name":"4.Exercise: Distinct Articles","notebookId":4067947267732497},"nbformat":4,"nbformat_minor":0}