{"cells":[{"cell_type":"markdown","source":["# Describe a DataFrame\n\nYour data processing in Azure Databricks is accomplished by defining Dataframes to read and process the Data.\n\nThis notebook will introduce how to read your data using Azure Databricks Dataframes."],"metadata":{}},{"cell_type":"markdown","source":["#Introduction\n\n** Data Source **\n* One hour of Pagecounts from the English Wikimedia projects captured August 5, 2016, at 12:00 PM UTC.\n* Size on Disk: ~23 MB\n* Type: Compressed Parquet File\n* More Info: <a href=\"https://dumps.wikimedia.org/other/pagecounts-raw\" target=\"_blank\">Page view statistics for Wikimedia projects</a>\n\n**Technical Accomplishments:**\n* Develop familiarity with the `DataFrame` APIs\n* Introduce the classes...\n  * `SparkSession`\n  * `DataFrame` (aka `Dataset[Row]`)\n* Introduce the actions...\n  * `count()`"],"metadata":{}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) **The Data Source**\n\n* In this notebook, we will be using a compressed parquet \"file\" called **pagecounts** (~23 MB file from Wikipedia)\n* We will explore the data and develop an understanding of it as we progress.\n* You can read more about this dataset here: <a href=\"https://dumps.wikimedia.org/other/pagecounts-raw/\" target=\"_blank\">Page view statistics for Wikimedia projects</a>.\n\nWe can use **dbutils.fs.ls()** to view our data on the DBFS."],"metadata":{}},{"cell_type":"code","source":["(source, sasEntity, sasToken) = getAzureDataSource()\n\nspark.conf.set(sasEntity, sasToken)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["path = source + \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\"\nfiles = dbutils.fs.ls(path)\ndisplay(files)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/_SUCCESS</td><td>_SUCCESS</td><td>0</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/_committed_6241970109963426653</td><td>_committed_6241970109963426653</td><td>760</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/_started_6241970109963426653</td><td>_started_6241970109963426653</td><td>0</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00000-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00000-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2996913</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00001-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00001-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2994285</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00002-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00002-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2994196</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00003-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00003-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2992431</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00004-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00004-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2990093</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00005-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00005-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2989931</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00006-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00006-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2989314</td></tr><tr><td>wasbs://training@dbtrainwestus.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00007-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00007-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2987499</td></tr></tbody></table></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["As we can see from the files listed above, this data is stored in <a href=\"https://parquet.apache.org\" target=\"_blank\">Parquet</a> files which can be read in a single command, the result of which will be a `DataFrame`."],"metadata":{}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Create a DataFrame\n* We can read the Parquet files into a `DataFrame`.\n* We'll start with the object **spark**, an instance of `SparkSession` and the entry point to Spark 2.0 applications.\n* From there we can access the `read` object which gives us an instance of `DataFrameReader`."],"metadata":{}},{"cell_type":"code","source":["parquetDir = source + \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\""],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["pagecountsEnAllDF = (spark  # Our SparkSession & Entry Point\n  .read                     # Our DataFrameReader\n  .parquet(parquetDir)      # Returns an instance of DataFrame\n)\nprint(pagecountsEnAllDF)    # Python hack to see the data type"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">DataFrame[project: string, article: string, requests: int, bytes_served: bigint]\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) count()\n\nIf you look at the API docs, `count()` is described like this:\n> Returns the number of rows in the Dataset.\n\n`count()` will trigger a job to process the request and return a value.\n\nWe can now count all records in our `DataFrame` like this:"],"metadata":{}},{"cell_type":"code","source":["total = pagecountsEnAllDF.count()\n\nprint(\"Record Count: {0:,}\".format( total ))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Record Count: 2,345,943\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["That tells us that there are around 2 million rows in the `DataFrame`."],"metadata":{}},{"cell_type":"markdown","source":["## Next steps\n\nStart the next lesson, [Use common DataFrame methods]($./2.Use-common-dataframe-methods)"],"metadata":{}}],"metadata":{"name":"1.Describe-a-dataframe","notebookId":4067947267732352},"nbformat":4,"nbformat_minor":0}